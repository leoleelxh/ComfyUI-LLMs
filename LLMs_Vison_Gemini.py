import os
import io
import json
import requests
import torch
import google.generativeai as genai
from io import BytesIO
from PIL import Image
from .settings import load_settings
import PIL.Image
import base64

p = os.path.dirname(os.path.realpath(__file__))


def get_gemini_api_key():
    try:
        all_settings = load_settings()
        api_key = all_settings['openai_compatible']['default']['vison_key_gemini']
    except:
        print("å‡ºé”™å•¦ Error: API key is required")
        return ""
    return api_key


def process_gemini(encoded_image, prompt, config):
    """å¤„ç†å›¾åƒå¹¶è¿”å›Geminiè§†è§‰æ¨¡å‹çš„å“åº”
    
    Args:
        encoded_image: base64ç¼–ç çš„å›¾åƒ
        prompt: æç¤ºè¯
        config: æ¨¡å‹é…ç½®ä¿¡æ¯
    
    Returns:
        str: æ¨¡å‹çš„å“åº”æ–‡æœ¬
    """
    try:
        # é…ç½®API
        genai.configure(api_key=config['api_key'])
        
        # åˆå§‹åŒ–æ¨¡å‹
        model = genai.GenerativeModel(config['model_list'][0])
        
        # è§£ç å›¾åƒ
        image_data = base64.b64decode(encoded_image)
        image = PIL.Image.open(BytesIO(image_data))
        
        # ç”Ÿæˆå“åº”
        response = model.generate_content([prompt, image])
        
        # è¿”å›ç»“æœ
        return response.text
        
    except Exception as e:
        return f"Geminiå¤„ç†å‡ºé”™: {str(e)}"


class LLMs_Vison_Gemini:
    """å·²åºŸå¼ƒçš„Geminiè§†è§‰èŠ‚ç‚¹ç±»ï¼Œè¯·ä½¿ç”¨æ–°çš„ç»Ÿä¸€è§†è§‰èŠ‚ç‚¹"""

    def __init__(self, api_key=None):

        all_settings = load_settings()
        self.api_key = all_settings['openai_compatible']['default']['vison_key_gemini']
        if self.api_key is not None:
            genai.configure(api_key=self.api_key, transport='rest')
        print("gemini_key:", self.api_key)

    @classmethod
    def INPUT_TYPES(cls):
        all_settings = load_settings()
        default_model = all_settings['openai_compatible']['default']['vision_model_gemini']
        return {
            "required": {
                "prompt": ("STRING", {"default": "Describe this image", "multiline": True}),
                "model_name": (default_model,),
                "stream": ("BOOLEAN", {"default": False}),
                # Add api_key as an input
                "api_key": ("STRING", {"default": ""})
            },
            "optional": {
                "image": ("IMAGE",),
            }
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("text",)
    FUNCTION = "generate_content"

    CATEGORY = "ğŸµ ComfyUI-LLMs"

    def tensor_to_image(self, tensor):
        # ç¡®ä¿å¼ é‡æ˜¯åœ¨CPUä¸Š
        tensor = tensor.cpu()

        # å°†å¼ é‡æ•°æ®è½¬æ¢ä¸º0-255èŒƒå›´å¹¶è½¬æ¢ä¸ºæ•´æ•°
        # è¿™é‡Œå‡è®¾å¼ é‡å·²ç»æ˜¯H x W x Cæ ¼å¼
        image_np = tensor.squeeze().mul(255).clamp(0, 255).byte().numpy()

        # åˆ›å»ºPILå›¾åƒ
        image = Image.fromarray(image_np, mode='RGB')
        return image

    def generate_content(self, prompt, model_name, stream, api_key, image=None):
        if api_key:
            self.api_key = api_key
            genai.configure(api_key=self.api_key, transport='rest')
        if not self.api_key:
            raise ValueError("API key is required")

        model = genai.GenerativeModel(model_name)

        if model_name == 'gemini-pro':
            if stream:
                response = model.generate_content(prompt, stream=True)
                textoutput = "\n".join([chunk.text for chunk in response])
            else:
                response = model.generate_content(prompt)
                textoutput = response.text

        if model_name == 'gemini-pro-vision':
            if image == None:
                raise ValueError("gemini-pro-vision needs image")
            else:
                # è½¬æ¢å›¾åƒ
                pil_image = self.tensor_to_image(image)

                # ç›´æ¥ä½¿ç”¨PILå›¾åƒ
                if stream:
                    response = model.generate_content(
                        [prompt, pil_image], stream=True)
                    textoutput = "\n".join([chunk.text for chunk in response])
                else:
                    response = model.generate_content([prompt, pil_image])
                    textoutput = response.text

        return (textoutput,)



